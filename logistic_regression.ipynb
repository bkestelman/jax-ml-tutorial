{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logistic_regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPUyEeeXrsZYLNSSKekPp//",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bkestelman/jax-ml-tutorial/blob/master/logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6YRmSlKSwVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jax\n",
        "import jax.numpy as np\n",
        "from jax import grad\n",
        "import numpy as onp # original numpy\n",
        "from random import randint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deW9n0hYS8q_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(x, W, b):\n",
        "  return W.dot(x) + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy5f9rtGTMJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(x, target, W, b):\n",
        "  return np.sum( (forward(x, W, b) - target)**2 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSSCzPoyTm7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backprop(x, target, W, b, learning_rate):\n",
        "  W -= grad(loss, argnums=2)(x, target, W, b) * learning_rate\n",
        "  b -= grad(loss, argnums=3)(x, target, W, b) * learning_rate\n",
        "  return W, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxRM_zMrUjMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_params(input_size, output_size):\n",
        "  W = onp.random.rand(output_size, input_size)\n",
        "  b = 0.0\n",
        "  return W, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRhuur_7XcEN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1578cef-7738-4ac3-c309-0a5fe49e576c"
      },
      "source": [
        "W, b = init_params(2, 1)\n",
        "print(W, b)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.21819811 0.9779639 ]] 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0yKMbWhVJ4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(X, labels, W, b, learning_rate):\n",
        "  for x, label in zip(X, labels):\n",
        "    W, b = backprop(x, label, W, b, learning_rate)\n",
        "  return W, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVYIO9KSZ3km",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(X, labels, W, b):\n",
        "  correct = 0\n",
        "  for x, label in zip(X, labels):\n",
        "    raw_pred = forward(x, W, b)\n",
        "    pred = 0 if raw_pred < 0.5 else 1\n",
        "    if pred == label:\n",
        "      correct += 1\n",
        "  print('Accuracy:', correct / len(X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyDiSgReXgXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = 200\n",
        "X = [ onp.random.randint(2, size=2) for _ in range(N) ]\n",
        "labels = [ np.array([float(X[0] and X[1])]) for X in X ]\n",
        "\n",
        "train_test_split = int(0.7 * N)\n",
        "train_X, train_labels = X[:train_test_split], labels[:train_test_split]\n",
        "test_X, test_labels = X[train_test_split:], labels[train_test_split:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaMFexmpgice",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test(test_X, test_labels, W, b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KvDhQ_jZGYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W, b = train(train_X, train_labels, W, b, learning_rate=0.01)\n",
        "print(W, b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bwp5JOZdZYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test(test_X, test_labels, W, b)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}