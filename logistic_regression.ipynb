{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logistic_regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPf41ZoyM8yBW4CaLtrCott",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bkestelman/jax-ml-tutorial/blob/master/logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHbUfcDMn2ok",
        "colab_type": "text"
      },
      "source": [
        "The main function we want from JAX is jax.grad(), which will automatically calculate gradients for us.\n",
        "\n",
        "We also import jax.numpy, which wraps numpy functions so that jax can calculate their derivatives while letting us use good ol' familiar numpy. \n",
        "\n",
        "We import regular numpy as onp (original numpy). We don't really need this, but it is convenient in a few special cases (like random numbers). We discuss this more later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6YRmSlKSwVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jax\n",
        "import jax.numpy as np\n",
        "from jax import grad\n",
        "import numpy as onp # original numpy\n",
        "from random import randint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7JgUSR9p4dJ",
        "colab_type": "text"
      },
      "source": [
        "Simple logistic regression (observe how we use jax.grad for back-propagation!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deW9n0hYS8q_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(x, W, b):\n",
        "  return W.dot(x) + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy5f9rtGTMJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(x, target, W, b):\n",
        "  return np.sum( (forward(x, W, b) - target)**2 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSSCzPoyTm7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backprop(x, target, W, b, learning_rate):\n",
        "  W -= grad(loss, argnums=2)(x, target, W, b) * learning_rate\n",
        "  b -= grad(loss, argnums=3)(x, target, W, b) * learning_rate\n",
        "  return W, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SjSrTJ4qMgj",
        "colab_type": "text"
      },
      "source": [
        "Initialize parameters (weight matrix and bias)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxRM_zMrUjMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_params(input_size, output_size):\n",
        "  W = onp.random.rand(output_size, input_size)\n",
        "  b = 0.0\n",
        "  return W, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRhuur_7XcEN",
        "colab_type": "code",
        "outputId": "184e091b-7777-4aaa-ce04-c2898a1de1ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "W, b = init_params(2, 1)\n",
        "print(W, b)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.94147518 0.32437763]] 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-oEbiItqSPn",
        "colab_type": "text"
      },
      "source": [
        "Define how to train and test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0yKMbWhVJ4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(X, labels, W, b, learning_rate):\n",
        "  for x, label in zip(X, labels):\n",
        "    W, b = backprop(x, label, W, b, learning_rate)\n",
        "  return W, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVYIO9KSZ3km",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(X, labels, W, b):\n",
        "  correct = 0\n",
        "  for x, label in zip(X, labels):\n",
        "    raw_pred = forward(x, W, b)\n",
        "    pred = 0 if raw_pred < 0.5 else 1\n",
        "    if pred == label:\n",
        "      correct += 1\n",
        "  print('Accuracy:', correct / len(X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exob-qokqhtt",
        "colab_type": "text"
      },
      "source": [
        "We will test if our logistic regression model can learn to solve boolean AND"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyDiSgReXgXa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "fa01cff2-468e-4c45-e592-a105d17d6e13"
      },
      "source": [
        "N = 200\n",
        "X = [ onp.random.randint(2, size=2) for _ in range(N) ]\n",
        "labels = [ np.array([float(X[0] and X[1])]) for X in X ]\n",
        "\n",
        "train_test_split = int(0.7 * N)\n",
        "train_X, train_labels = X[:train_test_split], labels[:train_test_split]\n",
        "test_X, test_labels = X[train_test_split:], labels[train_test_split:]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/jax/lib/xla_bridge.py:123: UserWarning: No GPU/TPU found, falling back to CPU.\n",
            "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRlRhbbzquSG",
        "colab_type": "text"
      },
      "source": [
        "First we test how it does without any training. This result will vary depending on the initial parameters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaMFexmpgice",
        "colab_type": "code",
        "outputId": "c7ca731b-b23c-475b-de51-6edac2af7b45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test(test_X, test_labels, W, b)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ypJjRY3rCCR",
        "colab_type": "text"
      },
      "source": [
        "Train the model and show the weights and bias after training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KvDhQ_jZGYE",
        "colab_type": "code",
        "outputId": "67f4d943-f4c0-4344-edf5-576b30d8ab29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "W, b = train(train_X, train_labels, W, b, learning_rate=0.01)\n",
        "print(W, b)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.6205038 0.3154657]] -0.24448743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eqbfRIgrGTJ",
        "colab_type": "text"
      },
      "source": [
        "Test again after training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bwp5JOZdZYE",
        "colab_type": "code",
        "outputId": "8f0a1317-d594-4178-c3a6-84dc36004b84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test(test_X, test_labels, W, b)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}