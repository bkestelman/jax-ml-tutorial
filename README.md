# JAX ML Tutorial

## ML from Scratch
A fun and important part of studying machine learning is building models from scratch - that is, without using the prebaked ones available in DL frameworks. What's not fun is calculating derivatives by hand and hard coding them into your models. 

## Automatic Differentiation and JAX
[JAX](https://github.com/google/jax) is a package for [automatic differentiation](https://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/slides/lec10.pdf), which is the fundamental technique that makes it possible for deep learning frameworks like Pytorch and Tensorflow to magically back-propagate all the derivatives through arbitrarily complex models. 

Here we will learn about and create many ML models from scratch while letting JAX take care of automatic differentiation for us. Let's get started!
